{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sklearn.decomposition\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "def load_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    return data\n",
    "\n",
    "df = load_data(\"./dataset/CLAMP_Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_magic</th>\n",
       "      <th>e_cblp</th>\n",
       "      <th>e_cp</th>\n",
       "      <th>e_crlc</th>\n",
       "      <th>e_cparhdr</th>\n",
       "      <th>e_minalloc</th>\n",
       "      <th>e_maxalloc</th>\n",
       "      <th>e_ss</th>\n",
       "      <th>e_sp</th>\n",
       "      <th>e_csum</th>\n",
       "      <th>...</th>\n",
       "      <th>CheckSum</th>\n",
       "      <th>Subsystem</th>\n",
       "      <th>DllCharacteristics</th>\n",
       "      <th>SizeOfStackReserve</th>\n",
       "      <th>SizeOfStackCommit</th>\n",
       "      <th>SizeOfHeapReserve</th>\n",
       "      <th>SizeOfHeapCommit</th>\n",
       "      <th>LoaderFlags</th>\n",
       "      <th>NumberOfRvaAndSizes</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>65452</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>119291</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>91168</td>\n",
       "      <td>3</td>\n",
       "      <td>320</td>\n",
       "      <td>262144</td>\n",
       "      <td>4096</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82656</td>\n",
       "      <td>2</td>\n",
       "      <td>32768</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   e_magic  e_cblp  e_cp  e_crlc  e_cparhdr  e_minalloc  e_maxalloc  e_ss   \n",
       "0    23117     144     3       0          4           0       65535     0  \\\n",
       "1    23117     144     3       0          4           0       65535     0   \n",
       "2    23117     144     3       0          4           0       65535     0   \n",
       "3    23117     144     3       0          4           0       65535     0   \n",
       "4    23117     144     3       0          4           0       65535     0   \n",
       "\n",
       "   e_sp  e_csum  ...  CheckSum  Subsystem  DllCharacteristics   \n",
       "0   184       0  ...     65452          2                1024  \\\n",
       "1   184       0  ...         0          2                   0   \n",
       "2   184       0  ...    119291          2                   0   \n",
       "3   184       0  ...     91168          3                 320   \n",
       "4   184       0  ...     82656          2               32768   \n",
       "\n",
       "   SizeOfStackReserve  SizeOfStackCommit  SizeOfHeapReserve  SizeOfHeapCommit   \n",
       "0             1048576               4096            1048576              4096  \\\n",
       "1             1048576               4096            1048576              4096   \n",
       "2             1048576               4096            1048576              4096   \n",
       "3              262144               4096            1048576              4096   \n",
       "4             1048576               4096            1048576              4096   \n",
       "\n",
       "   LoaderFlags  NumberOfRvaAndSizes  class  \n",
       "0            0                   16      0  \n",
       "1            0                   16      1  \n",
       "2            0                   16      0  \n",
       "3            0                   16      0  \n",
       "4            0                   16      1  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dataset_statistics(dataset:pd.DataFrame,target_col:str) -> tuple[int,int,int,int,float]:\n",
    "\n",
    "    #Total number of records\n",
    "    n_records = dataset.shape[0]\n",
    "    #Total number of columns \n",
    "    n_columns = len(dataset.columns)\n",
    "    #Number of records where target is negative\n",
    "    n_negative = dataset[target_col].value_counts()[0]\n",
    "    #Number of records where where target is positive\n",
    "    n_positive = dataset[target_col].value_counts()[1]\n",
    "    # Percentage of instances of positive target value\n",
    "    perc_positive =  (n_positive/n_records)*100\n",
    "\n",
    "    return n_records,n_columns,n_negative,n_positive,perc_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5, 5, 5, 50.0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def train_test_split(  dataset: pd.DataFrame,\n",
    "                       target_col: str, \n",
    "                       test_size: float,\n",
    "                       stratify: bool,\n",
    "                       random_state: int) -> tuple[pd.DataFrame,pd.DataFrame,pd.Series,pd.Series]:\n",
    "    \n",
    "#    split the dataset into train and test datasets\n",
    "    train, test = train_test_split(dataset, test_size=test_size, random_state=random_state, stratify=dataset[target_col] if stratify else None )\n",
    "\n",
    "    train_features = train.drop(target_col, axis=1)\n",
    "    test_features = test.drop(target_col, axis=1)\n",
    "    train_targets = train[target_col]\n",
    "    test_targets = test[target_col]\n",
    "\n",
    "    return train_features,test_features,train_targets,test_targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessDataset:\n",
    "    def __init__(self, \n",
    "                 train_features:pd.DataFrame, \n",
    "                 test_features:pd.DataFrame,\n",
    "                 one_hot_encode_cols:list[str],\n",
    "                 min_max_scale_cols:list[str],\n",
    "                 n_components:int,\n",
    "                 feature_engineering_functions:dict\n",
    "                 ):\n",
    "        # TODO: Add any state variables you may need to make your functions work\n",
    "        self.one_hot_encode_cols = one_hot_encode_cols\n",
    "        return\n",
    "\n",
    "    def one_hot_encode_columns_train(self) -> pd.DataFrame:\n",
    "        # TODO: Write the necessary code to create a dataframe with the categorical column names in \n",
    "        # the variable one_hot_encode_cols \"one hot\" encoded \n",
    "        ohe = OneHotEncoder()\n",
    "        transformed = ohe.fit_transform(self.one_hot_encode_cols)\n",
    "        one_hot_encoded_dataset = pd.DataFrame()\n",
    "\n",
    "        return one_hot_encoded_dataset\n",
    "\n",
    "    def one_hot_encode_columns_test(self) -> pd.DataFrame:\n",
    "        # TODO: Write the necessary code to create a dataframe with the categorical column names in \n",
    "        # the variable one_hot_encode_cols \"one hot\" encoded \n",
    "        one_hot_encoded_dataset = pd.DataFrame()\n",
    "\n",
    "        return one_hot_encoded_dataset\n",
    "\n",
    "    def min_max_scaled_columns_train(self) -> pd.DataFrame:\n",
    "        # TODO: Write the necessary code to create a dataframe with the numerical column names in \n",
    "        # the variable min_max_scale_cols scaled to the min and max of each column \n",
    "        min_max_scaled_dataset = pd.DataFrame()\n",
    "        return min_max_scaled_dataset\n",
    "\n",
    "    def min_max_scaled_columns_test(self) -> pd.DataFrame:\n",
    "        # TODO: Write the necessary code to create a dataframe with the numerical column names in \n",
    "        # the variable min_max_scale_cols scaled to the min and max of each column \n",
    "        min_max_scaled_dataset = pd.DataFrame()\n",
    "        return min_max_scaled_dataset\n",
    "    \n",
    "    def pca_train(self) -> pd.DataFrame:\n",
    "        # TODO: use PCA to reduce the train_df to n_components principal components\n",
    "        # Name your new columns component_1, component_2 .. component_n \n",
    "        pca_dataset = pd.DataFrame()\n",
    "        return pca_dataset\n",
    "\n",
    "    def pca_test(self) -> pd.DataFrame:\n",
    "        # TODO: use PCA to reduce the test_df to n_components principal components\n",
    "        # Name your new columns component_1, component_2 .. component_n \n",
    "        pca_dataset = pd.DataFrame()\n",
    "        return pca_dataset\n",
    "\n",
    "    def feature_engineering_train(self) -> pd.DataFrame:\n",
    "        # TODO: Write the necessary code to create a dataframe with feature engineering functions applied \n",
    "        # from the feature_engineering_functions dict (the dict format is {'feature_name':function,})\n",
    "        # each feature engineering function will take in type pd.DataFrame and return a pd.Series\n",
    "        feature_engineered_dataset = pd.DataFrame()\n",
    "        return feature_engineered_dataset\n",
    "\n",
    "    def feature_engineering_test(self) -> pd.DataFrame:\n",
    "        # TODO: Write the necessary code to create a dataframe with feature engineering functions applied \n",
    "        # from the feature_engineering_functions dict (the dict format is {'feature_name':function,})\n",
    "        # each feature engineering function will take in type pd.DataFrame and return a pd.Series\n",
    "        feature_engineered_dataset = pd.DataFrame()\n",
    "        return feature_engineered_dataset\n",
    "\n",
    "    def preprocess(self) -> tuple[pd.DataFrame,pd.DataFrame]:\n",
    "        # TODO: Use the functions you wrote above to create train/test splits of the features and target with scaled and encoded values \n",
    "        # for the columns specified in the init function\n",
    "        train_features = pd.DataFrame()\n",
    "        test_features = pd.DataFrame()\n",
    "        return train_features,test_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
