{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sklearn.decomposition\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import KElbowVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "def load_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    return data\n",
    "\n",
    "df = load_data(\"./dataset/CLAMP_Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_magic</th>\n",
       "      <th>e_cblp</th>\n",
       "      <th>e_cp</th>\n",
       "      <th>e_crlc</th>\n",
       "      <th>e_cparhdr</th>\n",
       "      <th>e_minalloc</th>\n",
       "      <th>e_maxalloc</th>\n",
       "      <th>e_ss</th>\n",
       "      <th>e_sp</th>\n",
       "      <th>e_csum</th>\n",
       "      <th>...</th>\n",
       "      <th>CheckSum</th>\n",
       "      <th>Subsystem</th>\n",
       "      <th>DllCharacteristics</th>\n",
       "      <th>SizeOfStackReserve</th>\n",
       "      <th>SizeOfStackCommit</th>\n",
       "      <th>SizeOfHeapReserve</th>\n",
       "      <th>SizeOfHeapCommit</th>\n",
       "      <th>LoaderFlags</th>\n",
       "      <th>NumberOfRvaAndSizes</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>65452</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>119291</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>91168</td>\n",
       "      <td>3</td>\n",
       "      <td>320</td>\n",
       "      <td>262144</td>\n",
       "      <td>4096</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82656</td>\n",
       "      <td>2</td>\n",
       "      <td>32768</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   e_magic  e_cblp  e_cp  e_crlc  e_cparhdr  e_minalloc  e_maxalloc  e_ss   \n",
       "0    23117     144     3       0          4           0       65535     0  \\\n",
       "1    23117     144     3       0          4           0       65535     0   \n",
       "2    23117     144     3       0          4           0       65535     0   \n",
       "3    23117     144     3       0          4           0       65535     0   \n",
       "4    23117     144     3       0          4           0       65535     0   \n",
       "\n",
       "   e_sp  e_csum  ...  CheckSum  Subsystem  DllCharacteristics   \n",
       "0   184       0  ...     65452          2                1024  \\\n",
       "1   184       0  ...         0          2                   0   \n",
       "2   184       0  ...    119291          2                   0   \n",
       "3   184       0  ...     91168          3                 320   \n",
       "4   184       0  ...     82656          2               32768   \n",
       "\n",
       "   SizeOfStackReserve  SizeOfStackCommit  SizeOfHeapReserve  SizeOfHeapCommit   \n",
       "0             1048576               4096            1048576              4096  \\\n",
       "1             1048576               4096            1048576              4096   \n",
       "2             1048576               4096            1048576              4096   \n",
       "3              262144               4096            1048576              4096   \n",
       "4             1048576               4096            1048576              4096   \n",
       "\n",
       "   LoaderFlags  NumberOfRvaAndSizes  class  \n",
       "0            0                   16      0  \n",
       "1            0                   16      1  \n",
       "2            0                   16      0  \n",
       "3            0                   16      0  \n",
       "4            0                   16      1  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dataset_statistics(dataset:pd.DataFrame,target_col:str) -> tuple[int,int,int,int,float]:\n",
    "\n",
    "    #Total number of records\n",
    "    n_records = dataset.shape[0]\n",
    "    #Total number of columns \n",
    "    n_columns = len(dataset.columns)\n",
    "    #Number of records where target is negative\n",
    "    n_negative = dataset[target_col].value_counts()[0]\n",
    "    #Number of records where where target is positive\n",
    "    n_positive = dataset[target_col].value_counts()[1]\n",
    "    # Percentage of instances of positive target value\n",
    "    perc_positive =  (n_positive/n_records)*100\n",
    "\n",
    "    return n_records,n_columns,n_negative,n_positive,perc_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def train_test_split(  dataset: pd.DataFrame,\n",
    "#                        target_col: str, \n",
    "#                        test_size: float,\n",
    "#                        stratify: bool,\n",
    "#                        random_state: int) -> tuple[pd.DataFrame,pd.DataFrame,pd.Series,pd.Series]:\n",
    "    \n",
    "# #    split the dataset into train and test datasets\n",
    "#     train, test = train_test_split(dataset, test_size=test_size, random_state=random_state, stratify=dataset[target_col] if stratify else None )\n",
    "\n",
    "#     train_features = train.drop(target_col, axis=1)\n",
    "#     test_features = test.drop(target_col, axis=1)\n",
    "#     train_targets = train[target_col]\n",
    "#     test_targets = test[target_col]\n",
    "\n",
    "#     return train_features,test_features,train_targets,test_targets\n",
    "\n",
    "def train_test_split(dataset: pd.DataFrame, target_col: str, test_size: float, stratify: bool = False, random_state: int = None):\n",
    "    if stratify:\n",
    "        # Split the dataset into positive and negative examples\n",
    "        positive = dataset[dataset[target_col] == 1]\n",
    "        negative = dataset[dataset[target_col] == 0]\n",
    "\n",
    "        # Calculate the number of positive and negative examples to include in the test set\n",
    "        n_positive_test = int(len(positive) * test_size)\n",
    "        n_negative_test = int(len(negative) * test_size)\n",
    "\n",
    "        # Randomly select positive and negative examples for the test set\n",
    "        positive_test = positive.sample(n_positive_test, random_state=random_state)\n",
    "        negative_test = negative.sample(n_negative_test, random_state=random_state)\n",
    "\n",
    "        # Combine the positive and negative test examples into a single DataFrame\n",
    "        test = pd.concat([positive_test, negative_test])\n",
    "\n",
    "        # Remove the test examples from the dataset to create the training set\n",
    "        train = dataset.drop(test.index)\n",
    "\n",
    "        # Split the training and test sets into features and targets\n",
    "        train_features = train.drop(target_col, axis=1)\n",
    "        train_targets = train[target_col]\n",
    "        test_features = test.drop(target_col, axis=1)\n",
    "        test_targets = test[target_col]\n",
    "\n",
    "        return train_features, test_features, train_targets, test_targets\n",
    "\n",
    "    else:\n",
    "        # If stratification is not required, simply split the data into training and test sets\n",
    "        train, test = sklearn.model_selection.train_test_split(dataset, test_size=test_size, random_state=random_state)\n",
    "        train_features = train.drop(target_col, axis=1)\n",
    "        train_targets = train[target_col]\n",
    "        test_features = test.drop(target_col, axis=1)\n",
    "        test_targets = test[target_col]\n",
    "\n",
    "        return train_features, test_features, train_targets, test_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessDataset:\n",
    "    def __init__(self, \n",
    "                 train_features:pd.DataFrame, \n",
    "                 test_features:pd.DataFrame,\n",
    "                 one_hot_encode_cols:list[str],\n",
    "                 min_max_scale_cols:list[str],\n",
    "                #  n_components:int,\n",
    "                #  feature_engineering_functions:dict\n",
    "                 ):\n",
    "        \n",
    "        self.one_hot_encode_cols = one_hot_encode_cols\n",
    "        self.test_features = test_features\n",
    "        self.train_features = train_features\n",
    "        self.min_max_scale_cols = min_max_scale_cols\n",
    "        return\n",
    "\n",
    "    def one_hot_encode_columns_train(self) -> pd.DataFrame:\n",
    "        \n",
    "        encoder = sklearn.preprocessing.OneHotEncoder(sparse_output=False)\n",
    "        encoded = encoder.fit_transform(self.train_features[self.one_hot_encode_cols])\n",
    "        column_names = encoder.get_feature_names_out(self.one_hot_encode_cols)\n",
    "        encoded = pd.DataFrame(encoded, columns=column_names, index=self.train_features.index)\n",
    "        train_features_encoded = pd.concat([encoded, self.train_features.drop(self.one_hot_encode_cols, axis=1)], axis=1)\n",
    "        \n",
    "        return train_features_encoded\n",
    "\n",
    "\n",
    "    def one_hot_encode_columns_test(self) -> pd.DataFrame:\n",
    "        # Split data into columns to be encoded and columns to be passed through\n",
    "        encode_cols = self.test_features[self.one_hot_encode_cols]\n",
    "        pass_cols = self.test_features.drop(self.one_hot_encode_cols, axis=1)\n",
    "        \n",
    "        # Fit OneHotEncoder on training data and transform test data\n",
    "        encoder = sklearn.preprocessing.OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        encoder.fit(self.train_features[self.one_hot_encode_cols])\n",
    "        encode_cols_encoded = pd.DataFrame(encoder.transform(encode_cols), index=encode_cols.index)\n",
    "        encode_cols_encoded.columns = encoder.get_feature_names_out(self.one_hot_encode_cols)\n",
    "        \n",
    "        # Join encoded and pass-through columns\n",
    "        test_features_encoded = pd.concat([encode_cols_encoded, pass_cols], axis=1)\n",
    "        \n",
    "        return test_features_encoded\n",
    "    \n",
    "    def min_max_scaled_columns_train(self) -> pd.DataFrame:\n",
    "\n",
    "        self.mms = sklearn.preprocessing.MinMaxScaler()\n",
    "        # scaled = mms.fit_transform(self.train_features[self.min_max_scale_cols])\n",
    "        self.mms.fit(self.train_features[self.min_max_scale_cols])\n",
    "        scaled = self.mms.transform(self.train_features[self.min_max_scale_cols])\n",
    "\n",
    "        # get column anmes\n",
    "        column_names = self.mms.get_feature_names_out(self.min_max_scale_cols)\n",
    "        min_max_scale_df = pd.DataFrame(scaled, columns=column_names, index=self.train_features.index)\n",
    "        # merging the min_max_scaled \n",
    "        min_max_scaled_dataset = pd.concat([min_max_scale_df, self.train_features.drop(self.min_max_scale_cols, axis=1)], axis=1)\n",
    "        \n",
    "        # print (scaled)\n",
    "        min_max_scaled_dataset\n",
    "        return min_max_scaled_dataset\n",
    "\n",
    "    def min_max_scaled_columns_test(self) -> pd.DataFrame:\n",
    "        \n",
    "        scaled = self.mms.transform(self.test_features[self.min_max_scale_cols])\n",
    "\n",
    "        # get column anmes\n",
    "        column_names = self.mms.get_feature_names_out(self.min_max_scale_cols)\n",
    "        min_max_scale_df = pd.DataFrame(scaled, columns=column_names, index=self.test_features.index)\n",
    "        # merging the min_max_scaled \n",
    "        min_max_scaled_dataset = pd.concat([min_max_scale_df, self.test_features.drop(self.min_max_scale_cols, axis=1)], axis=1)\n",
    "\n",
    "        return min_max_scaled_dataset\n",
    "    \n",
    "        \n",
    "    def pca_train(self) -> pd.DataFrame:\n",
    "\n",
    "        self.pca = sklearn.decomposition.PCA(n_components=self.n_components, random_state=0)\n",
    "        clean_df = self.train_features.dropna(axis=1)\n",
    "        self.pca.fit(clean_df)\n",
    "\n",
    "        pca_dataset = pd.DataFrame(self.pca.transform(clean_df), columns=[f\"component_{i+1}\" for i in range(self.n_components)])   \n",
    "\n",
    "        return pca_dataset\n",
    "\n",
    "    def pca_test(self) -> pd.DataFrame:\n",
    "        pca_dataset = pd.DataFrame(self.pca.transform(self.test_features), columns=[f\"component_{i+1}\" for i in range(self.n_components)])\n",
    "\n",
    "        return pca_dataset\n",
    "    \n",
    "    def feature_engineering_train(self) -> pd.DataFrame:\n",
    "        feature_engineered_dataset = self.train_features.copy()\n",
    "        for feature_name, function in self.feature_engineering_functions.items():\n",
    "            feature_engineered_dataset[feature_name] = function(self.train_features)\n",
    "        return feature_engineered_dataset\n",
    "\n",
    "    def feature_engineering_test(self) -> pd.DataFrame:\n",
    "        feature_engineered_dataset = self.test_features.copy()\n",
    "        for feature_name, function in self.feature_engineering_functions.items():\n",
    "            feature_engineered_dataset[feature_name] = function(self.test_features)\n",
    "        return feature_engineered_dataset\n",
    "    \n",
    "    def preprocess(self):\n",
    "        # One-hot encode and concatenate data\n",
    "        train_features_encoded = self.one_hot_encode_columns_train()\n",
    "        test_features_encoded = self.one_hot_encode_columns_test()\n",
    "\n",
    "        # Scale numerical columns using min-max scaling\n",
    "        train_features_scaled, test_features_scaled = self.min_max_scaled_columns_train(), self.min_max_scaled_columns_test()\n",
    "\n",
    "        # Apply feature engineering functions to data\n",
    "        train_features_engineered, test_features_engineered = self.feature_engineering_train(), self.feature_engineering_test()\n",
    "\n",
    "        # Combine encoded, scaled, and engineered data for training set with unique columns only\n",
    "        train_features_combined = pd.concat([train_features_scaled.iloc[:, 0], train_features_encoded.iloc[:, :-2], train_features_engineered.iloc[:, -2:]], axis=1, join='inner')\n",
    "        test_features_combined = pd.concat([test_features_scaled.iloc[:, 0], test_features_encoded.iloc[:, :-2], test_features_engineered.iloc[:, -2:]], axis=1, join='inner')\n",
    "\n",
    "        return train_features_combined, test_features_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class KmeansClustering:\n",
    "    def __init__(self, \n",
    "                 train_features:pd.DataFrame,\n",
    "                 test_features:pd.DataFrame,\n",
    "                 random_state: int\n",
    "                ):\n",
    "\n",
    "        self.train_features = train_features\n",
    "        self.test_features = test_features\n",
    "        self.random_state = random_state\n",
    "        pass\n",
    "\n",
    "    def kmeans_train(self) -> list:\n",
    "        kms = KMeans(random_state=self.random_state, n_init=10)\n",
    "        visualizer = KElbowVisualizer(kms(random_state=self.random_state),k=(1,10))\n",
    "        visualizer.fit(self.train_features)\n",
    "        self.optimal_k = visualizer.elbow_value_\n",
    "\n",
    "\n",
    "        kmeans = KMeans(n_clusters=self.optimal_k, random_state=self.random_state)\n",
    "        self.kmeans.fit(self.train_features)\n",
    "\n",
    "        # Get the cluster ids for each row of the training data\n",
    "        cluster_ids = kmeans.predict(self.train_features)\n",
    "\n",
    "        return cluster_ids.tolist()\n",
    "\n",
    "    def kmeans_test(self) -> list:\n",
    "        cluster_ids = self.kmeans.predict(self.test_features)\n",
    "        return cluster_ids.tolist()\n",
    "\n",
    "    def train_add_kmeans_cluster_id_feature(self) -> pd.DataFrame:\n",
    "        cluster_ids = self.kmeans_train()\n",
    "        # copy of the train data\n",
    "        train_data = self.train_features.copy()\n",
    "        train_data['kmeans_cluster_id'] = cluster_ids\n",
    "\n",
    "        return train_data\n",
    "\n",
    "    def test_add_kmeans_cluster_id_feature(self) -> pd.DataFrame:\n",
    "        cluster_ids = self.kmeans_test()\n",
    "\n",
    "        # copy of the test data\n",
    "        test_data = self.test_features.copy()\n",
    "        test_data['kmeans_cluster_id'] = cluster_ids\n",
    "        return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['e_magic', 'e_cblp', 'e_cp', 'e_crlc', 'e_cparhdr', 'e_minalloc',\n",
       "       'e_maxalloc', 'e_ss', 'e_sp', 'e_csum', 'e_ip', 'e_cs', 'e_lfarlc',\n",
       "       'e_ovno', 'e_res', 'e_oemid', 'e_oeminfo', 'e_res2', 'e_lfanew',\n",
       "       'Machine', 'NumberOfSections', 'CreationYear', 'PointerToSymbolTable',\n",
       "       'NumberOfSymbols', 'SizeOfOptionalHeader', 'Characteristics', 'Magic',\n",
       "       'MajorLinkerVersion', 'MinorLinkerVersion', 'SizeOfCode',\n",
       "       'SizeOfInitializedData', 'SizeOfUninitializedData',\n",
       "       'AddressOfEntryPoint', 'BaseOfCode', 'BaseOfData', 'ImageBase',\n",
       "       'SectionAlignment', 'FileAlignment', 'MajorOperatingSystemVersion',\n",
       "       'MinorOperatingSystemVersion', 'MajorImageVersion', 'MinorImageVersion',\n",
       "       'MajorSubsystemVersion', 'MinorSubsystemVersion', 'SizeOfImage',\n",
       "       'SizeOfHeaders', 'CheckSum', 'Subsystem', 'DllCharacteristics',\n",
       "       'SizeOfStackReserve', 'SizeOfStackCommit', 'SizeOfHeapReserve',\n",
       "       'SizeOfHeapCommit', 'LoaderFlags', 'NumberOfRvaAndSizes', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "# get dataset statistics\n",
    "n_records,n_columns,n_negative,n_positive,perc_positive = find_dataset_statistics(df,'class') \n",
    "# n_records,n_columns,n_negative,n_positive,perc_positive \n",
    "\n",
    "# split the dataset to train and test\n",
    "target_col = 'class'\n",
    "min_max_scale_cols = ['Characteristics', 'SizeOfCode','SizeOfInitializedData', 'AddressOfEntryPoint', 'BaseOfData', 'ImageBase', 'SizeOfImage', 'CheckSum', 'DllCharacteristics', 'SizeOfStackReserve']\n",
    "one_hot_encode_cols = ['MajorLinkerVersion','MinorLinkerVersion','MinorOperatingSystemVersion', 'MajorImageVersion', 'MinorImageVersion', 'MajorSubsystemVersion', 'Subsystem']\n",
    "# target_col\n",
    "train_features,test_features,train_targets,test_targets = train_test_split(df, target_col, test_size=0.2,stratify=True, random_state=42)\n",
    "\n",
    "train_features = pd.DataFrame(train_features)\n",
    "test_features = pd.DataFrame(test_features)\n",
    "\n",
    "preprocess = PreprocessDataset(train_features, test_features, one_hot_encode_cols,  min_max_scale_cols)\n",
    "\n",
    "\n",
    "ohe = preprocess.one_hot_encode_columns_train()\n",
    "# ohe.to_csv('new_df.csv')\n",
    "mms = preprocess.min_max_scaled_columns_train()\n",
    "mms.to_csv('new_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_values = df['MinorOperatingSystemVersion'].unique()\n",
    "class_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e_magic                          int64\n",
       "e_cblp                           int64\n",
       "e_cp                             int64\n",
       "e_crlc                           int64\n",
       "e_cparhdr                        int64\n",
       "e_minalloc                       int64\n",
       "e_maxalloc                       int64\n",
       "e_ss                             int64\n",
       "e_sp                             int64\n",
       "e_csum                           int64\n",
       "e_ip                             int64\n",
       "e_cs                             int64\n",
       "e_lfarlc                         int64\n",
       "e_ovno                           int64\n",
       "e_res                          float64\n",
       "e_oemid                          int64\n",
       "e_oeminfo                        int64\n",
       "e_res2                         float64\n",
       "e_lfanew                         int64\n",
       "Machine                          int64\n",
       "NumberOfSections                 int64\n",
       "CreationYear                     int64\n",
       "PointerToSymbolTable             int64\n",
       "NumberOfSymbols                  int64\n",
       "SizeOfOptionalHeader             int64\n",
       "Characteristics                  int64\n",
       "Magic                            int64\n",
       "MajorLinkerVersion               int64\n",
       "MinorLinkerVersion               int64\n",
       "SizeOfCode                       int64\n",
       "SizeOfInitializedData            int64\n",
       "SizeOfUninitializedData          int64\n",
       "AddressOfEntryPoint              int64\n",
       "BaseOfCode                       int64\n",
       "BaseOfData                       int64\n",
       "ImageBase                        int64\n",
       "SectionAlignment                 int64\n",
       "FileAlignment                    int64\n",
       "MajorOperatingSystemVersion      int64\n",
       "MinorOperatingSystemVersion      int64\n",
       "MajorImageVersion                int64\n",
       "MinorImageVersion                int64\n",
       "MajorSubsystemVersion            int64\n",
       "MinorSubsystemVersion            int64\n",
       "SizeOfImage                      int64\n",
       "SizeOfHeaders                    int64\n",
       "CheckSum                         int64\n",
       "Subsystem                        int64\n",
       "DllCharacteristics               int64\n",
       "SizeOfStackReserve               int64\n",
       "SizeOfStackCommit                int64\n",
       "SizeOfHeapReserve                int64\n",
       "SizeOfHeapCommit                 int64\n",
       "LoaderFlags                      int64\n",
       "NumberOfRvaAndSizes              int64\n",
       "class                            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_magic</th>\n",
       "      <th>e_cblp</th>\n",
       "      <th>e_cp</th>\n",
       "      <th>e_crlc</th>\n",
       "      <th>e_cparhdr</th>\n",
       "      <th>e_minalloc</th>\n",
       "      <th>e_maxalloc</th>\n",
       "      <th>e_ss</th>\n",
       "      <th>e_sp</th>\n",
       "      <th>e_csum</th>\n",
       "      <th>...</th>\n",
       "      <th>CheckSum</th>\n",
       "      <th>Subsystem</th>\n",
       "      <th>DllCharacteristics</th>\n",
       "      <th>SizeOfStackReserve</th>\n",
       "      <th>SizeOfStackCommit</th>\n",
       "      <th>SizeOfHeapReserve</th>\n",
       "      <th>SizeOfHeapCommit</th>\n",
       "      <th>LoaderFlags</th>\n",
       "      <th>NumberOfRvaAndSizes</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>65452</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>119291</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>91168</td>\n",
       "      <td>3</td>\n",
       "      <td>320</td>\n",
       "      <td>262144</td>\n",
       "      <td>4096</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82656</td>\n",
       "      <td>2</td>\n",
       "      <td>32768</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   e_magic  e_cblp  e_cp  e_crlc  e_cparhdr  e_minalloc  e_maxalloc  e_ss   \n",
       "0    23117     144     3       0          4           0       65535     0  \\\n",
       "1    23117     144     3       0          4           0       65535     0   \n",
       "2    23117     144     3       0          4           0       65535     0   \n",
       "3    23117     144     3       0          4           0       65535     0   \n",
       "4    23117     144     3       0          4           0       65535     0   \n",
       "\n",
       "   e_sp  e_csum  ...  CheckSum  Subsystem  DllCharacteristics   \n",
       "0   184       0  ...     65452          2                1024  \\\n",
       "1   184       0  ...         0          2                   0   \n",
       "2   184       0  ...    119291          2                   0   \n",
       "3   184       0  ...     91168          3                 320   \n",
       "4   184       0  ...     82656          2               32768   \n",
       "\n",
       "   SizeOfStackReserve  SizeOfStackCommit  SizeOfHeapReserve  SizeOfHeapCommit   \n",
       "0             1048576               4096            1048576              4096  \\\n",
       "1             1048576               4096            1048576              4096   \n",
       "2             1048576               4096            1048576              4096   \n",
       "3              262144               4096            1048576              4096   \n",
       "4             1048576               4096            1048576              4096   \n",
       "\n",
       "   LoaderFlags  NumberOfRvaAndSizes  class  \n",
       "0            0                   16      0  \n",
       "1            0                   16      1  \n",
       "2            0                   16      0  \n",
       "3            0                   16      0  \n",
       "4            0                   16      1  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
